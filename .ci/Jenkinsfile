#!/usr/bin/env groovy

@Library('apm@current') _

pipeline {
  agent { label 'ubuntu-20.04 && immutable' }
  environment {
    REPO = "synthetics-recorder"
    BASE_DIR = "src/github.com/elastic/${env.REPO}"
    DOCKER_REGISTRY = 'docker.elastic.co'
    DOCKER_ELASTIC_SECRET = 'secret/observability-team/ci/docker-registry/prod'
    JOB_GIT_CREDENTIALS = "f6c7695a-671e-4f4f-a331-acdce44ff9ba"
    PIPELINE_LOG_LEVEL = "INFO"
    NOTIFY_TO = 'synthrum+synthetics-recorder@elastic.co'
    SLACK_CHANNEL = '#observablt-bots'
  }
  options {
    timeout(time: 2, unit: 'HOURS')
    buildDiscarder(logRotator(numToKeepStr: '20', artifactNumToKeepStr: '20', daysToKeepStr: '30'))
    timestamps()
    ansiColor('xterm')
    disableResume()
    durabilityHint('PERFORMANCE_OPTIMIZED')
    rateLimitBuilds(throttle: [count: 60, durationName: 'hour', userBoost: true])
    quietPeriod(10)
  }
  stages {
    stage('Checkout') {
      options { skipDefaultCheckout() }
      steps {
        whenTrue(isInternalCI() && isTag()) {
          notifyStatus(slackStatus: 'good', subject: "[${env.REPO}] Build for the release tag *${env.TAG_NAME}* has been triggered", body: "Build: (<${env.RUN_DISPLAY_URL}|here>) for further details.")
        }
        pipelineManager([ cancelPreviousRunningBuilds: [ when: 'PR' ] ])
        deleteDir()
        gitCheckout(basedir: "${BASE_DIR}", githubNotifyFirstTimeContributor: true)
        stash(allowEmpty: true, name: 'source', useDefaultExcludes: false)
        // Fail fast if no access to docker login
        retryWithSleep(retries: 3, seconds: 10, backoff: true) {
          dockerLogin(secret: "${DOCKER_ELASTIC_SECRET}", registry: "${DOCKER_REGISTRY}")
        }
      }
    }
    stage('Release') {
      options { skipDefaultCheckout() }
      when {
        beforeAgent true
        allOf {
          tag pattern: 'v\\d+\\.\\d+.*', comparator: 'REGEXP'
          expression { isInternalCI() }
        }
      }
      environment {
        BUCKET_NAME = 'internal-ci-artifacts'
        BUCKET_SUBFOLDER = "${env.REPO}/${env.TAG_NAME}/${env.BUILD_ID}"
        BUCKET_PATH = "gs://${env.BUCKET_NAME}/${env.BUCKET_SUBFOLDER}"
        BUCKET_CREDENTIALS = 'internal-ci-gcs-plugin'
        SIGNED_ARTIFACTS = 'signed-artifacts'
        BUCKET_SUBFOLDER_SIGNED_ARTIFACTS = "${env.BUCKET_SUBFOLDER}/${env.SIGNED_ARTIFACTS}"
        BUCKET_SIGNED_ARTIFACTS_PATH = "gs://${env.BUCKET_NAME}/${env.BUCKET_SUBFOLDER_SIGNED_ARTIFACTS}"
        DIST_FOLDER = 'dist'
        RELEASE_URL_MESSAGE = "(<https://github.com/elastic/${env.REPO}/releases/tag/${env.TAG_NAME}|${env.TAG_NAME}>)"
      }
      // There are some environmental issues with some of the CI workers
      // let's use the one we know it works.
      // agent { label 'macos-code-signer' }
      agent { label 'worker-c07yc0cejyvy' }
      stages {
        stage('Dist') {
          options { skipDefaultCheckout() }
          steps {
            deleteDir()
            unstash 'source'
            withNodeJSEnv() {
              dir("${BASE_DIR}"){
                runReleaseWithKeychain()
              }
            }
          }
          post {
            success {
              dir("${BASE_DIR}"){
                stash(allowEmpty: false, name: 'exe', includes: "${env.DIST_FOLDER}/*.exe")
              }
            }
          }
        }
        stage('Signing Windows') {
          agent { label 'cloud-hsm' }
          options { skipDefaultCheckout() }
          environment {
            BASE_DIR_WIN = "${BASE_DIR.replaceAll('\\/', '\\\\')}"
          }
          steps {
            deleteDir()
            unstash 'source'
            unstash('exe')
            withAzureSigningCreds {
              dir("${env.DIST_FOLDER}") {
                getFirstExeFileName()
                bat(label: 'ACS signing', script: "${env.WORKSPACE}\\${BASE_DIR_WIN}\\.ci\\scripts\\acs-signing.bat ${env.WORKSPACE}\\${env.DIST_FOLDER}\\${env.EXE_FILE_NAME}")
                stash(includes: "${env.EXE_FILE_NAME}", name: 'signed_exe', allowEmpty: false)
              }
            }
          }
          post {
            cleanup {
              deleteDir()
            }
          }
        }
        stage('Signing *Nix') {
          options { skipDefaultCheckout() }
          steps {
            dir("${BASE_DIR}") {
              uploadBinariesToBeSigned(['deb', 'dmg', 'zip'])
              build(job: 'elastic+unified-release+master+sign-artifacts-with-gpg',
                    parameters: [string(name: 'gcs_input_path', value: "${env.BUCKET_PATH}")],
                    wait: true,
                    propagate: true)
            }
          }
        }
        stage('Download signed artifacts') {
          options { skipDefaultCheckout() }
          steps {
            dir("${BASE_DIR}/${SIGNED_ARTIFACTS}") {
              downloadSignedBinaries()
            }
          }
        }
        stage('Publish S3 Artifacts') {
          options { skipDefaultCheckout() }
          agent { label 'ubuntu-20.04 && immutable' }  // Required to run within the context of an ephemeral worker so docker is available
          steps {
            deleteDir()
            retryWithSleep(retries: 3, seconds: 10, backoff: true) {
              dockerLogin(secret: "${DOCKER_ELASTIC_SECRET}", registry: "${DOCKER_REGISTRY}")
            }
            unstash 'source'
            dir("${BASE_DIR}/${SIGNED_ARTIFACTS}") {
              downloadSignedBinaries()
            }
            dir("${BASE_DIR}") {
              withS3Creds {
                sh(label: 'publish-s3-artifacts.sh', script: '.ci/scripts/publish-s3-artifacts.sh "${SIGNED_ARTIFACTS}/${DIST_FOLDER}"')
              }
            }
          }
        }
        stage('Publish GitHub Release') {
          options { skipDefaultCheckout() }
          steps {
            dir("${BASE_DIR}") {
              withCredentials([string(credentialsId: '2a9602aa-ab9f-4e52-baf3-b71ca88469c7', variable: 'GITHUB_TOKEN')]) {
                sh(label: 'create-github-release.sh', script: '.ci/scripts/create-github-release.sh')
              }
            }
          }
        }
      }
      post {
        success {
          notifyStatus(slackStatus: 'good', subject: "[${env.REPO}] Release *${env.TAG_NAME}* published", body: "Build: (<${env.RUN_DISPLAY_URL}|here>), Github Release: ${RELEASE_URL_MESSAGE}")
        }
        failure {
          notifyStatus(slackStatus: 'warning', subject: "[${env.REPO}] Release *${env.TAG_NAME}* could not be published", body: "Build: (<${env.RUN_DISPLAY_URL}|here>)")
        }
        cleanup {
          deleteDir()
        }
      }
    }
  }
}

def notifyStatus(def args = [:]) {
  releaseNotification(slackChannel: "${env.SLACK_CHANNEL}",
                      slackColor: args.slackStatus,
                      slackCredentialsId: 'jenkins-slack-integration-token',
                      to: "${env.NOTIFY_TO}",
                      subject: args.subject,
                      body: args.body)
}

def downloadSignedBinaries() {
  googleStorageDownload(bucketUri: "${env.BUCKET_SIGNED_ARTIFACTS_PATH}/*",
                        credentialsId: env.BUCKET_CREDENTIALS,
                        localDirectory: "${DIST_FOLDER}/",
                        pathPrefix: "${env.BUCKET_SUBFOLDER_SIGNED_ARTIFACTS}")
  dir("${env.DIST_FOLDER}") {
    unstash 'signed_exe'
  }
  archiveArtifacts(allowEmptyArchive: false, artifacts: "${DIST_FOLDER}/*.*")
}

def uploadBinariesToBeSigned(extensions = [:]) {
  extensions?.each { extension ->
    googleStorageUpload(bucket: env.BUCKET_PATH,
                        credentialsId: env.BUCKET_CREDENTIALS,
                        pathPrefix: "${env.DIST_FOLDER}/",
                        pattern: "${env.DIST_FOLDER}/*.${extension}",
                        sharedPublicly: false,
                        showInline: true)
  }
}

def runReleaseWithKeychain() {
  def vault = getVaultSecret(secret: 'secret/observability-team/ci/synthetics-recorder-macos-vault').data
  if (!vault.containsKey('vault_secret_id') || !vault.containsKey('vault_role_id') || !vault.containsKey('vault_addr')) {
    error("runReleaseWithKeychain: macos secret could not be accessed correctly")
  }
  def token = getVaultSecret.getVaultToken(vault.vault_addr, vault.vault_role_id, vault.vault_secret_id)
  def apple = getVaultSecret.getVaultSecretObject(vault.vault_addr, 'secret/release/apple-2023', token).data
  if (!apple.containsKey('keychain-password') || !apple.containsKey('username') || !apple.containsKey('app-specific-password')) {
    error("runReleaseWithKeychain: apple secret must contain username, app-specific-password")
  }
  withEnvMask(vars: [
    [var: 'KEYCHAIN_PASSWORD', password: apple.get('keychain-password')],
    [var: 'APPLE_USERNAME', password: apple.get('username')],
    [var: 'APPLE_APP_SPECIFIC_PASSWORD', password: apple.get('app-specific-password')],
  ]){
    sh(label: 'release-ci.sh', script: '.ci/scripts/release-ci.sh')
  }
}

def withAzureSigningCreds(Closure body) {
  def syntheticsRecorderWindowsVault = 'secret/observability-team/ci/synthetics-recorder-windows-vault'
  def vault = getVaultSecret(secret: syntheticsRecorderWindowsVault).data
  if (!vault.containsKey('vault_secret_id') || !vault.containsKey('vault_role_id') || !vault.containsKey('vault_addr')) {
    error("withAzureSigningCreds: ${syntheticsRecorderWindowsVault} secert must contain vault_secret_id, vault_role_id and vault_addr entries")
  }
  def token = getVaultSecret.getVaultToken(vault.vault_addr, vault.vault_role_id, vault.vault_secret_id)
  def cloudHsmPath = 'secret/release/cloud-hsm'
  def azureSecrets = getVaultSecret.getVaultSecretObject(vault.vault_addr, cloudHsmPath, token).data
  if (!azureSecrets.containsKey('azure-tenant-id') || !azureSecrets.containsKey('azure-client-id') || !azureSecrets.containsKey('azure-client-secret')) {
    error("withAzureSigningCreds: ${cloudHsmPath} must contain azure-tenant-id, azure-client-id and azure-client-secret entries")
  }

  withEnvMask(vars: [
    [var: "AZURE_TENANT_ID", password: azureSecrets['azure-tenant-id']],
    [var: "AZURE_CLIENT_ID", password: azureSecrets['azure-client-id']],
    [var: "AZURE_CLIENT_SECRET", password: azureSecrets['azure-client-secret']]
    ]) {
      body()
  }
}

/*
Sets EXE_FILE_NAME env var as first found exe file in current dir
*/
def getFirstExeFileName() {
  def files = findFiles(glob: '*.exe')
  env.EXE_FILE_NAME = "${files[0].name}"
}

def withS3Creds(Closure body) {
  def vault = getVaultSecret(secret: 'secret/observability-team/ci/synthetics-recorder-macos-vault').data
  if (!vault.containsKey('vault_secret_id') || !vault.containsKey('vault_role_id') || !vault.containsKey('vault_addr')) {
    error("withS3Creds: s3 secret could not be accessed correctly")
  }
  def token = getVaultSecret.getVaultToken(vault.vault_addr, vault.vault_role_id, vault.vault_secret_id)
  def s3 = readAWS(vault.vault_addr, 'aws-elastic/sts/synthetics-recorder', token).data
  if (!s3.containsKey('access_key') || !s3.containsKey('secret_key')) {
    error("withS3Creds: s3 secret must contain access_key and secret_key")
  }

  withEnvMask(vars: [
    [var: 'AWS_ACCESS_KEY_ID', password: s3.get('access_key')],
    [var: 'AWS_SECRET_ACCESS_KEY', password: s3.get('secret_key')],
  ]){
    body()
  }
}

def readAWS(addr, secret, token) {
  wrap([$class: 'MaskPasswordsBuildWrapper', varPasswordPairs: [
    [var: 'VAULT_SECRET', password: secret],
    [var: 'VAULT_TOKEN', password: token],
    [var: 'VAULT_ADDR', password: addr],
  ]]) {
    // sts secrets use write rather than read
    // vault write -f <sts-secret>
    def retJson =  httpRequest(url: "${addr}/v1/${secret}",
                               method: 'POST',
                               headers: ['X-Vault-Token': "${token}", 'Content-Type': 'application/json'])
    def obj = toJSON(retJson)
    if(!(obj instanceof net.sf.json.JSONObject)){
      error("readAWS: Unable to get the secret.")
    }
    return obj
  }
}
