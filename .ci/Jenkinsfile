#!/usr/bin/env groovy

@Library('apm@current') _

pipeline {
  agent { label 'ubuntu-20.04 && immutable' }
  environment {
    REPO = "synthetics-recorder"
    BASE_DIR = "src/github.com/elastic/${env.REPO}"
    DOCKER_REGISTRY = 'docker.elastic.co'
    DOCKER_ELASTIC_SECRET = 'secret/observability-team/ci/docker-registry/prod'
    JOB_GIT_CREDENTIALS = "f6c7695a-671e-4f4f-a331-acdce44ff9ba"
    PIPELINE_LOG_LEVEL = "INFO"
    NOTIFY_TO = 'synthrum+synthetics-recorder@elastic.co'
    SLACK_CHANNEL = '#observablt-bots'
  }
  options {
    timeout(time: 2, unit: 'HOURS')
    buildDiscarder(logRotator(numToKeepStr: '20', artifactNumToKeepStr: '20', daysToKeepStr: '30'))
    timestamps()
    ansiColor('xterm')
    disableResume()
    durabilityHint('PERFORMANCE_OPTIMIZED')
    rateLimitBuilds(throttle: [count: 60, durationName: 'hour', userBoost: true])
    quietPeriod(10)
  }
  triggers {
    issueCommentTrigger("(${obltGitHubComments()}|^/test all)")
  }
  stages {
    stage('Checkout') {
      options { skipDefaultCheckout() }
      steps {
        whenTrue(isInternalCI() && isTag()) {
          notifyStatus(slackStatus: 'good', subject: "[${env.REPO}] Build for the release tag *${env.TAG_NAME}* has been triggered", body: "Build: (<${env.RUN_DISPLAY_URL}|here>) for further details.")
        }
        pipelineManager([ cancelPreviousRunningBuilds: [ when: 'PR' ] ])
        deleteDir()
        gitCheckout(basedir: "${BASE_DIR}", githubNotifyFirstTimeContributor: true)
        stash(allowEmpty: true, name: 'source', useDefaultExcludes: false)
        dir("${BASE_DIR}") {
          setEnvVar('DOCKER_CHANGES', isGitRegionMatch(patterns: [ '^e2e/Dockerfile.jenkins' ], shouldMatchAll: false).toString())
        }
      }
    }
    stage('Install') {
      options { skipDefaultCheckout() }
      when {
        beforeAgent true
        expression { return !isTag() }
      }
      steps {
        withGithubNotify(context: "Install") {
          withNodeJSEnv() {
            dir("${BASE_DIR}") {
              sh(label: 'npm ci', script: 'npm ci')
            }
          }
        }
      }
    }
    stage('Lint') {
      options { skipDefaultCheckout() }
      when {
        beforeAgent true
        expression { return !isTag() }
      }
      steps {
        withGithubNotify(context: "Lint") {
          withNodeJSEnv() {
            dir("${BASE_DIR}"){
              sh(label: 'npm lint', script: 'npm run lint')
            }
          }
        }
        withGithubNotify(context: "Unused exports") {
          withNodeJSEnv() {
            dir("${BASE_DIR}"){
              sh(label: 'npm unused-exports', script: 'npm run unused-exports')
            }
          }
        }
      }
      post {
        always {
          archiveArtifacts(allowEmptyArchive: true, artifacts: "${BASE_DIR}/eslint-junit.xml")
          junit(allowEmptyResults: true, keepLongStdio: true, testResults: "${BASE_DIR}/eslint-junit.xml")
        }
      }
    }
    stage('Build'){
      options { skipDefaultCheckout() }
      when {
        beforeAgent true
        expression { return !isTag() }
      }
      steps {
        withGithubNotify(context: "Build") {
          withNodeJSEnv() {
            dir("${BASE_DIR}"){
              sh(label: 'npm build', script: 'npm run build')
            }
          }
        }
      }
    }
    stage('Release') {
      options { skipDefaultCheckout() }
      when {
        beforeAgent true
        allOf {
          tag pattern: 'v\\d+\\.\\d+.*', comparator: 'REGEXP'
          expression { isInternalCI() }
        }
      }
      environment {
        BUCKET_NAME = 'internal-ci-artifacts'
        BUCKET_SUBFOLDER = "${env.REPO}/${env.TAG_NAME}/${env.BUILD_ID}"
        BUCKET_PATH = "gs://${env.BUCKET_NAME}/${env.BUCKET_SUBFOLDER}"
        BUCKET_CREDENTIALS = 'internal-ci-gcs-plugin'
        SIGNED_ARTIFACTS = 'signed-artifacts'
        BUCKET_SUBFOLDER_SIGNED_ARTIFACTS = "${env.BUCKET_SUBFOLDER}/${env.SIGNED_ARTIFACTS}"
        BUCKET_SIGNED_ARTIFACTS_PATH = "gs://${env.BUCKET_NAME}/${env.BUCKET_SUBFOLDER_SIGNED_ARTIFACTS}"
        DIST_FOLDER = 'dist'
        RELEASE_URL_MESSAGE = "(<https://github.com/elastic/${env.REPO}/releases/tag/${env.TAG_NAME}|${env.TAG_NAME}>)"
      }
      // There are some environmental issues with some of the CI workers
      // let's use the one we know it works.
      // agent { label 'macos-code-signer' }
      agent { label 'worker-c07yc0cejyvy' }
      stages {
        stage('Dist') {
          options { skipDefaultCheckout() }
          steps {
            deleteDir()
            unstash 'source'
            withNodeJSEnv() {
              dir("${BASE_DIR}"){
                runReleaseWithKeychain()
              }
            }
          }
          post {
            success {
              dir("${BASE_DIR}"){
                stash(allowEmpty: false, name: 'exe', includes: "${env.DIST_FOLDER}/*.exe")
              }
            }
          }
        }
        stage('Signing Windows') {
          agent { label 'cloud-hsm' }
          options { skipDefaultCheckout() }
          environment {
            BASE_DIR_WIN = "${BASE_DIR.replaceAll('\\/', '\\\\')}"
          }
          steps {
            deleteDir()
            unstash 'source'
            unstash('exe')
            withAzureSigningCreds {
              dir("${env.DIST_FOLDER}") {
                getFirstExeFileName()                
                bat(label: 'ACS signing', script: "${env.WORKSPACE}\\${BASE_DIR_WIN}\\.ci\\scripts\\acs-signing.bat ${env.WORKSPACE}\\${env.DIST_FOLDER}\\${env.EXE_FILE_NAME}")
                stash(includes: "${env.EXE_FILE_NAME}", name: 'signed_exe', allowEmpty: false)
              }
            }
          }
          post {
            cleanup {
              deleteDir()
            }
          }
        }
        stage('Signing *Nix') {
          options { skipDefaultCheckout() }
          steps {
            dir("${BASE_DIR}") {
              uploadBinariesToBeSigned(['deb', 'dmg', 'zip'])
              build(job: 'elastic+unified-release+master+sign-artifacts-with-gpg',
                    parameters: [string(name: 'gcs_input_path', value: "${env.BUCKET_PATH}")],
                    wait: true,
                    propagate: true)
            }
          }
        }
        stage('Download signed artifacts') {
          options { skipDefaultCheckout() }
          steps {
            dir("${BASE_DIR}/${SIGNED_ARTIFACTS}") {
              downloadSignedBinaries()
            }
          }
        }
        stage('Publish GitHub Release') {
          options { skipDefaultCheckout() }
          steps {
            dir("${BASE_DIR}") {
              withCredentials([string(credentialsId: '2a9602aa-ab9f-4e52-baf3-b71ca88469c7', variable: 'GITHUB_TOKEN')]) {
                sh(label: 'create-github-release.sh', script: '.ci/scripts/create-github-release.sh "${SIGNED_ARTIFACTS}/${DIST_FOLDER}"')
              }
            }
          }
        }
      }
      post {
        success {
          notifyStatus(slackStatus: 'good', subject: "[${env.REPO}] Release *${env.TAG_NAME}* published", body: "Build: (<${env.RUN_DISPLAY_URL}|here>), Github Release: ${RELEASE_URL_MESSAGE}")
        }
        failure {
          notifyStatus(slackStatus: 'warning', subject: "[${env.REPO}] Release *${env.TAG_NAME}* could not be published", body: "Build: (<${env.RUN_DISPLAY_URL}|here>)")
        }
        cleanup {
          deleteDir()
        }
      }
    }
  }
  post {
    cleanup {
      // Reporting disables in the `internal-ci` since credentials are not in place
      // OTOH it avoids duplicated notifications
      whenFalse(isInternalCI()){
        notifyBuildResult(prComment: true)
      }
    }
  }
}

def notifyStatus(def args = [:]) {
  releaseNotification(slackChannel: "${env.SLACK_CHANNEL}",
                      slackColor: args.slackStatus,
                      slackCredentialsId: 'jenkins-slack-integration-token',
                      to: "${env.NOTIFY_TO}",
                      subject: args.subject,
                      body: args.body)
}

def downloadSignedBinaries() {
  googleStorageDownload(bucketUri: "${env.BUCKET_SIGNED_ARTIFACTS_PATH}/*",
                        credentialsId: env.BUCKET_CREDENTIALS,
                        localDirectory: "${DIST_FOLDER}/",
                        pathPrefix: "${env.BUCKET_SUBFOLDER_SIGNED_ARTIFACTS}")
  dir("${env.DIST_FOLDER}") {
    unstash 'signed_exe'
  }                      
  archiveArtifacts(allowEmptyArchive: false, artifacts: "${DIST_FOLDER}/*.*")
}

def uploadBinariesToBeSigned(extensions = [:]) {
  extensions?.each { extension ->
    googleStorageUpload(bucket: env.BUCKET_PATH,
                        credentialsId: env.BUCKET_CREDENTIALS,
                        pathPrefix: "${env.DIST_FOLDER}/",
                        pattern: "${env.DIST_FOLDER}/*.${extension}",
                        sharedPublicly: false,
                        showInline: true)
  }
}

def runReleaseWithKeychain() {
  def vault = getVaultSecret(secret: 'secret/observability-team/ci/synthetics-recorder-macos-vault').data
  if (!vault.containsKey('vault_secret_id') || !vault.containsKey('vault_role_id') || !vault.containsKey('vault_addr')) {
    error("runReleaseWithKeychain: macos secret could not be accessed correctly")
  }
  def token = getVaultSecret.getVaultToken(vault.vault_addr, vault.vault_role_id, vault.vault_secret_id)
  def apple = getVaultSecret.getVaultSecretObject(vault.vault_addr, 'secret/release/apple', token).data
  if (!apple.containsKey('keychain-password') || !apple.containsKey('username') || !apple.containsKey('app-specific-password')) {
    error("runReleaseWithKeychain: apple secret must contain username, app-specific-password")
  }
  withEnvMask(vars: [
    [var: 'KEYCHAIN_PASSWORD', password: apple.get('keychain-password')],
    [var: 'APPLE_USERNAME', password: apple.get('username')],
    [var: 'APPLE_APP_SPECIFIC_PASSWORD', password: apple.get('app-specific-password')],
  ]){
    sh(label: 'release-ci.sh', script: '.ci/scripts/release-ci.sh')
  }
}

def withAzureSigningCreds(Closure body) {
  def syntheticsRecorderWindowsVault = 'secret/observability-team/ci/synthetics-recorder-windows-vault'
  def vault = getVaultSecret(secret: syntheticsRecorderWindowsVault).data
  if (!vault.containsKey('vault_secret_id') || !vault.containsKey('vault_role_id') || !vault.containsKey('vault_addr')) {
    error("withAzureSigningCreds: ${syntheticsRecorderWindowsVault} secert must contain vault_secret_id, vault_role_id and vault_addr entries")
  }
  def token = getVaultSecret.getVaultToken(vault.vault_addr, vault.vault_role_id, vault.vault_secret_id)  
  def cloudHsmPath = 'secret/release/cloud-hsm'
  def azureSecrets = getVaultSecret.getVaultSecretObject(vault.vault_addr, cloudHsmPath, token).data
  if (!azureSecrets.containsKey('azure-tenant-id') || !azureSecrets.containsKey('azure-client-id') || !azureSecrets.containsKey('azure-client-secret')) {
    error("withAzureSigningCreds: ${cloudHsmPath} must contain azure-tenant-id, azure-client-id and azure-client-secret entries")
  }
  
  withEnvMask(vars: [
    [var: "AZURE_TENANT_ID", password: azureSecrets['azure-tenant-id']],
    [var: "AZURE_CLIENT_ID", password: azureSecrets['azure-client-id']],
    [var: "AZURE_CLIENT_SECRET", password: azureSecrets['azure-client-secret']]
    ]) {        
      body()
  }
}

/*
Sets EXE_FILE_NAME env var as first found exe file in current dir
*/
def getFirstExeFileName() {
  def files = findFiles(glob: '*.exe')
  env.EXE_FILE_NAME = "${files[0].name}"
}
